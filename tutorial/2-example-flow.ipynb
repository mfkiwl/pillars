{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2c7b91",
   "metadata": {},
   "source": [
    "# An Example Design Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484c2f6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val ivy_path = System.getProperty(\"user.dir\") + \"/load-ivy.sc\"\n",
    "interp.load.module(ammonite.ops.Path(java.nio.file.FileSystems.getDefault().getPath(ivy_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Date\n",
    "import chisel3.iotesters\n",
    "import chisel3.iotesters.PeekPokeTester\n",
    "import pillars.archlib.TileLSUBlock\n",
    "import pillars.core._\n",
    "import pillars.hardware.{SynthesizedModule, TopModule}\n",
    "import pillars.mapping.{DFG, DotReader, ILPMap, OmtMap, SearchMap}\n",
    "import pillars.testers.{AppTestHelper, ApplicationTester}\n",
    "\n",
    "import chiseltest._\n",
    "import chiseltest.iotesters.PeekPokeTester\n",
    "import chiseltest.simulator.VerilatorBackendAnnotation\n",
    "import org.scalatest.flatspec.AnyFlatSpec\n",
    "import sys.process._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3bab2",
   "metadata": {},
   "source": [
    "## Define an end-to-end flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6581638",
   "metadata": {},
   "outputs": [],
   "source": [
    "object Tutorial {\n",
    "  def main(args: Array[String]): Unit = {\n",
    "    /** Prepare runtime information manually.\n",
    "     *\n",
    "     * @param dfg     the data-flow graph\n",
    "     * @param numSRAM the number of SRAM in a CGRA tile\n",
    "     * @return the runtime information\n",
    "     */\n",
    "    def prepareRuntimeInfo(dfg: DFG, numSRAM: Int) = {\n",
    "      val dataSize = 50\n",
    "      val VectorA = (0 until dataSize).map(_ => scala.math.abs(scala.util.Random.nextInt() % 1000)).toArray\n",
    "      val VectorB = (0 until dataSize).map(_ => scala.math.abs(scala.util.Random.nextInt() % 1000)).toArray\n",
    "\n",
    "      //Input random indexes into the mapped input port in CGRA,\n",
    "      // and get A(index) + B(index) from the mapped output port.\n",
    "      val inputIndexes = scala.util.Random.shuffle((0 until dataSize).toList)\n",
    "      val expectedRet = (0 until dataSize).map(i => VectorA(inputIndexes(i)) + VectorB(inputIndexes(i)))\n",
    "\n",
    "      //The base address of A and B in SRAM of an LSU.\n",
    "      //To simplify the problem, we assume both A and B are stored\n",
    "      //in all SRAMs belonging to 4 LSUs in the targeted architecture.\n",
    "      val a_base = 0\n",
    "      val b_base = dataSize\n",
    "\n",
    "      //The value of const operators.\n",
    "      val const0 = a_base\n",
    "      val const1 = b_base\n",
    "      val const2 = dataSize - 1\n",
    "      val const3 = a_base\n",
    "      val const4 = a_base\n",
    "      val constVals = Array(const0, const1, const2, const3, const4)\n",
    "\n",
    "      val constOpNames = dfg.opNodes.filter(op => op.opcode == OpEnum.CONST).map(op => op.name)\n",
    "      val constValue = (0 until constOpNames.size).map(i => ConstValue(constOpNames(i), constVals(i))).toList\n",
    "\n",
    "      //Operator incr0 should generate (j <- 0 until dataSize).\n",
    "      //So the parameter of the counter is (init = 0, step = 1, end = dataSize, freq = 1)\n",
    "      val counterOpNames = dfg.opNodes.filter(op => op.opcode == OpEnum.INCR).map(op => op.name)\n",
    "      val counterConfig = List(CounterConfig(counterOpNames(0), 0, 1, dataSize, 1))\n",
    "\n",
    "      //In this simple tutorial, A and B are put into all LSUs.\n",
    "      //But you can put them into partial LSUs according to the mapping results,\n",
    "      // just like what in the ApplicationExamples.\n",
    "      //Because the PEs in a row share an LSU, the number of LSUs is rowNum.\n",
    "      val inputToSRAM = (0 until numSRAM).map(i => InputToSRAM(i, a_base, VectorA.toList)).toList :::\n",
    "        (0 until numSRAM).map(i => InputToSRAM(i, b_base, VectorB.toList)).toList\n",
    "\n",
    "      val outputFromSRAM = List(OutputFromSRAM(3, a_base, VectorA.reverse.toList))\n",
    "\n",
    "      //Please make sure there are 2 operators with INPUT opcode in the DFG.\n",
    "      val inputOpNames = dfg.opNodes.filter(op => op.opcode == OpEnum.INPUT).map(op => op.name)\n",
    "      val inputToPort = List(InputToPort(inputOpNames(0), inputIndexes))\n",
    "\n",
    "      val outputOpNames = dfg.opNodes.filter(op => op.opcode == OpEnum.OUTPUT).map(op => op.name)\n",
    "      val outputFromPort = List(OutputFromPort(outputOpNames(0), expectedRet.toList))\n",
    "\n",
    "      val runtimeInfo = RuntimeInfo(inputToPort, outputFromPort, inputToSRAM\n",
    "        , outputFromSRAM, constValue, counterConfig)\n",
    "\n",
    "      runtimeInfo\n",
    "    }\n",
    "\n",
    "    val rowNum = 4\n",
    "    val colNum = 4\n",
    "    val inputPort = 4\n",
    "    val outputPort = 4\n",
    "    val dataWidth = 32\n",
    "\n",
    "    //Initialize the top block.\n",
    "    val arch = new ArchitectureHierarchy()\n",
    "    arch.addInPorts((0 until inputPort).map(i => s\"input_$i\").toArray)\n",
    "    arch.addOutPorts((0 until outputPort).map(i => s\"out_$i\").toArray)\n",
    "\n",
    "    val tile = new TileLSUBlock(\"tile_0\", colNum, rowNum, inputPort, outputPort,\n",
    "      useMuxBypass = false, complex = true, isToroid = false, useCounter = true, dataWidth = dataWidth)\n",
    "    arch.addBlock(tile)\n",
    "\n",
    "    (0 until inputPort).foreach(i =>\n",
    "      arch.addConnect(arch.term(s\"input_$i\") -> tile / s\"input_$i\"))\n",
    "    (0 until outputPort).foreach(i =>\n",
    "      arch.addConnect(tile / s\"out_$i\" -> arch.term(s\"out_$i\")))\n",
    "    arch.init()\n",
    "\n",
    "    //Get MRRG and mapping.\n",
    "    //You can also use dumpMRRG(targetedII, filename) to save the MRRG,\n",
    "    // and use loadTXT(mrrgFilename) to load the MRRG.\n",
    "    val II = 1\n",
    "    val MRRG = arch.getMRRG(II)\n",
    "    val dfgFilename = \"Vadd_Reverse.dot\"\n",
    "    val dfg = DotReader.loadDot(dfgFilename, II)\n",
    "    val mappingResultFilename = s\"ii$II\"\n",
    "\n",
    "    object Solver extends Enumeration {\n",
    "      val Gurobi, Search, Z3Prover = Value\n",
    "    }\n",
    "    val solver = Solver.Search\n",
    "    val separatedPR = true\n",
    "    val scheduleControl = true\n",
    "\n",
    "    var startTime = new Date().getTime()\n",
    "    solver match {\n",
    "      case Solver.Gurobi => ILPMap.mapping(dfg, MRRG, filename = mappingResultFilename, separatedPR = separatedPR, scheduleControl = scheduleControl, skewLimit = 4, latencyLimit = 15)\n",
    "      case Solver.Search => SearchMap.mapping(dfg, MRRG, mappingResultFilename, scheduleControl = scheduleControl, skewLimit = 4)\n",
    "      case Solver.Z3Prover => OmtMap.mapping(dfg, MRRG, filename = mappingResultFilename, separatedPR = separatedPR, scheduleControl = scheduleControl, skewLimit = 4, latencyLimit = 15)\n",
    "    }\n",
    "    var endTime = new Date().getTime()\n",
    "    println(\"Mapping runtime: \" + (endTime - startTime))\n",
    "\n",
    "    // PillarsConfig.USE_TOKEN = true\n",
    "\n",
    "    //Generate the top design.\n",
    "    val connect = new Connect(arch.connectArray)\n",
    "    val hardwareGenerator = new HardwareGenerator(arch, connect)\n",
    "    val topDesign = () => new TopModule(hardwareGenerator.pillarsModuleInfo,\n",
    "      hardwareGenerator.connectMap, hardwareGenerator.regionList, dataWidth)\n",
    "\n",
    "    //Generate the RTL codes.\n",
    "    //chisel3.emitVerilog(topDesign(), Array(\"-td\", \"RTL/\"))\n",
    "\n",
    "    //Simulate with the mapping result.\n",
    "    JsonParser.writeJson(prepareRuntimeInfo(dfg, rowNum), \"runtime.json\")\n",
    "    val runtimeInfo = JsonParser.readJson(\"runtime.json\")\n",
    "\n",
    "    //Simulation settings.\n",
    "    val simulationHelper = new SimulationHelper(arch)\n",
    "    val resultFilename = s\"ii$II\" + \"_r.txt\"\n",
    "    simulationHelper.init(resultFilename, runtimeInfo, II)\n",
    "\n",
    "    val appTestHelper = new AppTestHelper(II)\n",
    "    val moduleInfoFilename = s\"ii$II\" + \"_i.txt\"\n",
    "    appTestHelper.init(arch, simulationHelper, moduleInfoFilename, runtimeInfo)\n",
    "\n",
    "    //JsonParser.dumpRuntimeInfo(simulationHelper, appTestHelper, dfg)\n",
    "\n",
    "    org.scalatest.run(new AnyFlatSpec with ChiselScalatestTester {\n",
    "      it should \"work\" in {\n",
    "        test(topDesign())\n",
    "        .withAnnotations(Seq(VerilatorBackendAnnotation))\n",
    "        .runPeekPoke(new VaddReverseTester(_, appTestHelper))\n",
    "      }\n",
    "    })\n",
    "  }\n",
    "}\n",
    "\n",
    "/** A tester for vec-add + vec-reverse application.\n",
    " *\n",
    " * @param c             the top design\n",
    " * @param appTestHelper the class which is helpful when creating testers\n",
    " */\n",
    "class VaddReverseTester(c: TopModule, appTestHelper: AppTestHelper)\n",
    "  extends ApplicationTester(c, appTestHelper) {\n",
    "\n",
    "  poke(c.io.en, 0)\n",
    "  inputData()\n",
    "  val testII = appTestHelper.getTestII()\n",
    "  inputConfig(testII)\n",
    "  poke(c.io.en, 1)\n",
    "  checkPortOutsWithInput(testII)\n",
    "\n",
    "  //Wait reverse finished\n",
    "  step(10)\n",
    "  checkLSUData()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01176b",
   "metadata": {},
   "source": [
    "## Execute the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438eddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tutorial.main(Array())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
